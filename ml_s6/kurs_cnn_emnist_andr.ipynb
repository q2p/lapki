{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import EMNIST\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from emnist import list_datasets\n",
    "from emnist import extract_training_samples\n",
    "from emnist import extract_test_samples\n",
    "\n",
    "print(list_datasets())\n",
    "\n",
    "X_train, y_train = extract_training_samples('letters')\n",
    "\n",
    "print(\"train shape:\", X_train.shape)\n",
    "print(\"train labels:\", y_train.shape)\n",
    "\n",
    "X_test, y_test = extract_test_samples('letters')\n",
    "\n",
    "print(\"test shape:\", X_test.shape)\n",
    "print(\"test labels:\", y_test.shape)\n",
    "np.array(np.unique(y_train, return_counts=True)).T\n",
    "\n",
    "np.array(np.unique(y_test, return_counts=True)).T\n",
    "\n",
    "import string\n",
    "def plot_sample(index):\n",
    "    plt.matshow(X_train[index], cmap='binary')\n",
    "    n = y_train[index] + ord('a') - 1;\n",
    "    print(\"letter:\", chr(n), \"\\nindex:\", y_train[index])\n",
    "\n",
    "plot_sample(0)\n",
    "\n",
    "plot_sample(1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 27)\n",
    "Y_test = np_utils.to_categorical(y_test, 27)\n",
    "\n",
    "EPOCHS = 5\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "KERNEL_SIZE = (3,3)\n",
    "BATCH_SIZE = 64\n",
    "DROPRATE = 0.25\n",
    "CLASSES = 27\n",
    "VALIDATION_DATA = (X_test, Y_test)\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "\n",
    "cnn = models.Sequential([\n",
    "    layers.Convolution2D(filters=32, \n",
    "                         kernel_size=KERNEL_SIZE, \n",
    "                         padding = 'same', \n",
    "                         activation ='relu', \n",
    "                         input_shape=INPUT_SHAPE),\n",
    "    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding = 'same'),\n",
    "\n",
    "    layers.Convolution2D(filters=64, \n",
    "                         kernel_size=KERNEL_SIZE,\n",
    "                         padding = 'same',\n",
    "                         activation ='relu',\n",
    "                         input_shape=INPUT_SHAPE),\n",
    "    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding = 'same'),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(DROPRATE),\n",
    "    layers.Dense(CLASSES, activation = 'softmax')\n",
    "])\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/base\", histogram_freq=1)\n",
    "\n",
    "history = cnn.fit(X_train, \n",
    "                  Y_train, \n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=EPOCHS, \n",
    "                  verbose=VERBOSE, \n",
    "                  validation_data=VALIDATION_DATA, \n",
    "                  callbacks=[tb_callback])\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"C:/Users/pereg/-- machine learning/logs\"\n",
    "\n",
    "score = cnn.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "print(\"Test accuracy: %.4f%%\" % (score[1]*100))\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "y_predicted = cnn.predict(X_test)\n",
    "\n",
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]\n",
    "\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
